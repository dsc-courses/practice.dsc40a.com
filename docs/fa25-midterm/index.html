<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Fall 2025 Midterm</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../assets/theme.css" />
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Fall 2025 Midterm</h1>
</header>
<p><link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
<!-- add after bootstrap.min.css -->
<link rel="stylesheet" href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css"/>
<!-- add after bootstrap.min.js or bootstrap.bundle.min.js -->
<script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script></p>
<!-- for difficulty gauges-->
<script src="https://cdn.plot.ly/plotly-2.16.1.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-B947E6J6H4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-B947E6J6H4');
</script>
<p><a href="../index.html">‚Üê return to practice.dsc40a.com</a></p>
<hr />
<p><strong>Instructor(s):</strong> Gal Mishne</p>
<p>This exam was administered in person. They had a two sided 11in by
8.5in cheat sheet. Students had <strong>50 minutes</strong> to take this
exam.</p>
<hr />
<h2 id="problem-1">Problem 1</h2>
<p>You are working in a biology laboratory to quantify how an antibiotic
drug influences the population growth of <em>E. coli</em> bacteria. You
inoculate a Petri dish with the bacteria and the drug, then monitor the
culture over time. At measurement times <span class="math inline">x_1,
x_2, \dotsc, x_n</span> (hours since inoculation), you estimate the
total bacterial count <span class="math inline">y_1, y_2, \dotsc,
y_n</span>. To describe the growth pattern, you propose the exponential
model <span class="math display">H(x) = h\,e^{-x}, \qquad h \in
\mathbb{R}.</span></p>
<p>Note: in version B the given function was <span
class="math inline">H(x)=he^x</span>.</p>
<p><br></p>
<h3 id="problem-1.1">Problem 1.1</h3>
<p>Using the squared loss function <span
class="math inline">\ell_{sq}(h, (x_i, y_i)) = (he^{-x_i} -
y_i)^2</span>, clearly write down the associated empirical risk as a
function of <span class="math inline">h</span>.</p>
<div id="accordionExample" class="accordion">
<div class="accordion-item">
<h2 class="accordion-header" id="heading1_1">
<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapse1_1" aria-expanded="true" aria-controls="collapse1_1">
Click to view the solution.
</button>
</h2>
<div id="collapse1_1" class="accordion-collapse collapse"
aria-labelledby="heading1_1" data-bs-parent="#accordionExample">
<div class="accordion-body">
<header id="title-block-header">
<h1 class="title"> </h1>
</header>
<p><strong>Version A:</strong> <span class="math display">R(h)\;=\;\frac{1}{n}\sum_{i=1}^n\big(he^{-x_i}-y_i\big)^2.</span></p>
<p><strong>Version B:</strong> <span class="math display">R(h)\;=\;\frac{1}{n}\sum_{i=1}^n\big(he^{x_i}-y_i\big)^2.</span></p>
</div>
</div>
</div>
</div>
<p><br></p>
<h3 id="problem-1.2">Problem 1.2</h3>
<p>Compute <span class="math inline">\frac{d}{dh} R(h)</span>.</p>
<div id="accordionExample" class="accordion">
<div class="accordion-item">
<h2 class="accordion-header" id="heading1_2">
<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapse1_2" aria-expanded="true" aria-controls="collapse1_2">
Click to view the solution.
</button>
</h2>
<div id="collapse1_2" class="accordion-collapse collapse"
aria-labelledby="heading1_2" data-bs-parent="#accordionExample">
<div class="accordion-body">
<header id="title-block-header">
<h1 class="title"> </h1>
</header>
<p><strong>Version A:</strong></p>
<p><span class="math display">R(h)=\frac{1}{n}\sum_{i=1}^n\big(he^{-x_i}-y_i\big)^2</span></p>
<p>Differentiate term‚Äìby‚Äìterm (chain rule): <span class="math display">\frac{d}{dh}R(h)=\frac{1}{n}\sum_{i=1}^n
2\big(he^{-x_i}-y_i\big)\cdot e^{-x_i}
=\frac{2}{n}\left(h\sum_{i=1}^n e^{-2x_i}-\sum_{i=1}^n y_i
e^{-x_i}\right).</span></p>
<p>Equivalently, expanding the square, <span class="math display">R(h)=\frac{1}{n}\sum_{i=1}^n\!\left(h^2e^{-2x_i}-2hy_ie^{-x_i}+y_i^2\right)
\;\Rightarrow\; R'(h)=\frac{2}{n}\left(h\sum e^{-2x_i}-\sum
y_ie^{-x_i}\right).</span></p>
<p><strong>Version B:</strong></p>
<p><span class="math display">R(h)=\frac{1}{n}\sum_{i=1}^n\big(he^{x_i}-y_i\big)^2</span></p>
<p>Differentiate term‚Äìby‚Äìterm (chain rule): <span class="math display">\frac{d}{dh}R(h)=\frac{1}{n}\sum_{i=1}^n
2\big(he^{x_i}-y_i\big)\cdot e^{x_i}
=\frac{2}{n}\left(h\sum_{i=1}^n e^{2x_i}-\sum_{i=1}^n y_i
e^{x_i}\right).</span></p>
</div>
</div>
</div>
</div>
<p><br></p>
<h3 id="problem-1.3">Problem 1.3</h3>
<p>Prove that the global minimizer <span
class="math inline">h^\ast</span> for <span
class="math inline">R(h)</span> is given by the formula <span
class="math display">h^\ast \;=\; \frac{\sum_{i=1}^n y_i
e^{-x_i}}{\sum_{i=1}^n e^{-2x_i}}.</span></p>
<div id="accordionExample" class="accordion">
<div class="accordion-item">
<h2 class="accordion-header" id="heading1_3">
<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapse1_3" aria-expanded="true" aria-controls="collapse1_3">
Click to view the solution.
</button>
</h2>
<div id="collapse1_3" class="accordion-collapse collapse"
aria-labelledby="heading1_3" data-bs-parent="#accordionExample">
<div class="accordion-body">
<header id="title-block-header">
<h1 class="title"> </h1>
</header>
<p><strong>Version A:</strong></p>
<p>Set the derivative to zero: <span class="math display">0=\frac{2}{n}\left(h^\ast\sum_{i=1}^n
e^{-2x_i}-\sum_{i=1}^n y_i e^{-x_i}\right)
\;\Longrightarrow\;
h^\ast\sum_{i=1}^n e^{-2x_i}=\sum_{i=1}^n y_i e^{-x_i}</span> <span class="math display">h^\ast=\frac{\sum_{i=1}^n y_i
e^{-x_i}}{\sum_{i=1}^n e^{-2x_i}}.</span></p>
<p>Uniqueness: <span class="math inline">R(h)</span> is a quadratic with
<span class="math display">R''(h)=\frac{2}{n}\sum_{i=1}^n
e^{-2x_i}&gt;0</span></p>
<p>Since <span class="math inline">e^{-2x_i}&gt;0</span> for all <span class="math inline">i</span>, <span class="math inline">R'' &gt;
0</span> and the critical point is the unique minimizer.</p>
<p><strong>Version B:</strong></p>
<p>Set the derivative to zero: <span class="math display">0=\frac{2}{n}\left(h^\ast\sum_{i=1}^n
e^{2x_i}-\sum_{i=1}^n y_i e^{x_i}\right)
\;\Longrightarrow\;
h^\ast=\frac{\sum_{i=1}^n y_i e^{x_i}}{\sum_{i=1}^n
e^{2x_i}}.</span></p>
<p>Uniqueness: <span class="math inline">R(h)</span> is a quadratic with
<span class="math display">R''(h)=\frac{2}{n}\sum_{i=1}^n
e^{2x_i}&gt;0</span></p>
<p>Since <span class="math inline">e^{2x_i}&gt;0</span> for all <span class="math inline">i</span>, <span class="math inline">R'' &gt;
0</span> and the critical point is the unique minimizer.</p>
</div>
</div>
</div>
</div>
<p><br></p>
<h3 id="problem-1.4">Problem 1.4</h3>
<p>After talking to a colleague, you decide to use the following
hypothesis function instead: <span class="math display">\widetilde{H}(x)
= h_0 + h_1e^{-x}.</span></p>
<p>Using a suitable data transformation (i.e., change of variables) and
formulas we have derived in class, find a formula for the optimal
parameters <span class="math inline">h_0^\ast, h_1^\ast</span> which
minimize the mean squared error for the hypothesis function <span
class="math inline">\widetilde{H}(x)</span> given your observations from
before.</p>
<div id="accordionExample" class="accordion">
<div class="accordion-item">
<h2 class="accordion-header" id="heading1_4">
<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapse1_4" aria-expanded="true" aria-controls="collapse1_4">
Click to view the solution.
</button>
</h2>
<div id="collapse1_4" class="accordion-collapse collapse"
aria-labelledby="heading1_4" data-bs-parent="#accordionExample">
<div class="accordion-body">
<header id="title-block-header">
<h1 class="title"> </h1>
</header>
<p><strong>For Version A:</strong></p>
<p>Let <span class="math inline">z_i:=e^{-x_i}</span>. Then <span class="math inline">\widetilde{H}(x)=h_0+h_1e^{-x}=h_0+h_1 z</span> is
ordinary simple linear regression of <span class="math inline">y</span>
on <span class="math inline">z</span> with MSE.</p>
<p><strong>For Version B:</strong></p>
<p>Let <span class="math inline">z_i:=e^{x_i}</span>. Then <span class="math inline">\widetilde{H}(x)=h_0+h_1e^{x}=h_0+h_1 z</span> is
ordinary simple linear regression of <span class="math inline">y</span>
on <span class="math inline">z</span> with MSE.</p>
<p><strong>The rest of the solution is the same for both
versions:</strong></p>
<p>With <span class="math inline">\bar z=\frac{1}{n}\sum z_i</span> and
<span class="math inline">\bar y=\frac{1}{n}\sum y_i</span>, <span class="math display">h_1^\ast=\frac{\sum_{i=1}^n (z_i-\bar z)(y_i-\bar
y)}{\sum_{i=1}^n (z_i-\bar z)^2},
\qquad
h_0^\ast=\bar y-h_1^\ast\,\bar z.</span></p>
<p>Equivalently, by the normal equations <span class="math display">\begin{bmatrix} n &amp; \sum z_i\\[2pt] \sum z_i
&amp; \sum z_i^2 \end{bmatrix}
\begin{bmatrix} h_0^\ast\\ h_1^\ast \end{bmatrix}
=
\begin{bmatrix} \sum y_i\\ \sum z_i y_i \end{bmatrix}.</span></p>
<p><strong>Alternative solution:</strong></p>
<p>Let the design matrix be <span class="math display">\mathbf{X} =
\begin{bmatrix}
1 &amp; z_1 \\
1 &amp; z_2 \\
\vdots &amp; \vdots \\
1 &amp; z_n \\                 
\end{bmatrix}</span></p>
<p>Then by the normal equations <span class="math display">\mathbf{X}^T\mathbf{X} h =\mathbf{X}^Ty</span></p>
</div>
</div>
</div>
</div>
<p><br></p>
<hr />
<h2 id="problem-2">Problem 2</h2>
<p>For each of the following statements, <strong>clearly</strong> fill
in <strong>TRUE</strong> or <strong>FALSE</strong>. You do not need to
show any work to earn full credit, but you can provide justification to
possibly earn partial credit.</p>
<p>In parts <strong>(a)</strong>‚Äì<strong>(d)</strong>, let <span
class="math inline">\{(\vec{x}_i, y_i)\}_{i=1}^n</span> be a fixed
dataset, where each <span class="math inline">\vec{x}_i \in
\mathbb{R}^d</span> and <span class="math inline">y_i \in
\mathbb{R}</span>. Let <span class="math inline">X \in \mathbb{R}^{n
\times (d+1)}</span> be the corresponding design matrix defined in the
usual way. (For simple linear regression, <span class="math inline">d =
1</span> and each <span class="math inline">\vec{x}_i</span> is a
scalar.)</p>
<p><br></p>
<h3 id="problem-2.1">Problem 2.1</h3>
<p>For a simple linear regression model: <span
class="math display">\min_{\vec{w} = (w_0, w_1)}
\frac{1}{n}\sum_{i=1}^{n} |y_i -(w_0+w_1x_i)| = \min_{\vec{w} = (w_0,
w_1)} \frac{1}{n} \| \vec{y} - X\vec{w}\|.</span></p>
<p>TRUE or FALSE?</p>
<div id="accordionExample" class="accordion">
<div class="accordion-item">
<h2 class="accordion-header" id="heading2_1">
<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapse2_1" aria-expanded="true" aria-controls="collapse2_1">
Click to view the solution.
</button>
</h2>
<div id="collapse2_1" class="accordion-collapse collapse"
aria-labelledby="heading2_1" data-bs-parent="#accordionExample">
<div class="accordion-body">
<header id="title-block-header">
<h1 class="title"> </h1>
</header>
<p><strong>FALSE.</strong> LHS is MAE (L‚ÇÅ); RHS is the Euclidean norm
(L‚ÇÇ). They minimize different objectives.</p>
</div>
</div>
</div>
</div>
<p><br></p>
<h3 id="problem-2.2">Problem 2.2</h3>
<p><span class="math inline">\nabla \|X\vec{w} - \vec{y}\|^2 = X^\top X
\vec{w} - X^\top \vec{y}</span>.</p>
<p>TRUE or FALSE?</p>
<div id="accordionExample" class="accordion">
<div class="accordion-item">
<h2 class="accordion-header" id="heading2_2">
<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapse2_2" aria-expanded="true" aria-controls="collapse2_2">
Click to view the solution.
</button>
</h2>
<div id="collapse2_2" class="accordion-collapse collapse"
aria-labelledby="heading2_2" data-bs-parent="#accordionExample">
<div class="accordion-body">
<header id="title-block-header">
<h1 class="title"> </h1>
</header>
<p><strong>FALSE.</strong> <span class="math inline">\nabla\|X\vec
w-\vec y\|^2=2X^\top(X\vec w-\vec y)=2X^\top X\vec w-2X^\top \vec
y</span> (missing factor 2).</p>
</div>
</div>
</div>
</div>
<p><br></p>
<h3 id="problem-2.3">Problem 2.3</h3>
<p><span class="math inline">d+1 = \mathrm{rank}(X^\top X) +
\textrm{dim}(\mathrm{null}(X) )</span>.</p>
<p>TRUE or FALSE?</p>
<div id="accordionExample" class="accordion">
<div class="accordion-item">
<h2 class="accordion-header" id="heading2_3">
<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapse2_3" aria-expanded="true" aria-controls="collapse2_3">
Click to view the solution.
</button>
</h2>
<div id="collapse2_3" class="accordion-collapse collapse"
aria-labelledby="heading2_3" data-bs-parent="#accordionExample">
<div class="accordion-body">
<header id="title-block-header">
<h1 class="title"> </h1>
</header>
<p><strong>TRUE.</strong> Rank‚Äìnullity: <span class="math inline">\mathrm{rank}(X)+\mathrm{null}(X)=d+1</span> and
<span class="math inline">\mathrm{rank}(X^\top
X)=\mathrm{rank}(X)</span>.</p>
</div>
</div>
</div>
</div>
<p><br></p>
<h3 id="problem-2.4">Problem 2.4</h3>
<p>If the columns of <span class="math inline">X</span> are orthonormal
(so <span class="math inline">X^\top X = I</span>), then the optimal
parameter <span class="math inline">w_i^\ast</span> is given by <span
class="math inline">w_{i}^\ast = \vec{c}_i\cdot \vec{y}</span>, where
<span class="math inline">\vec{c}_i</span> is the <span
class="math inline">i</span>-th column of <span
class="math inline">X</span>.</p>
<p>TRUE or FALSE?</p>
<div id="accordionExample" class="accordion">
<div class="accordion-item">
<h2 class="accordion-header" id="heading2_4">
<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapse2_4" aria-expanded="true" aria-controls="collapse2_4">
Click to view the solution.
</button>
</h2>
<div id="collapse2_4" class="accordion-collapse collapse"
aria-labelledby="heading2_4" data-bs-parent="#accordionExample">
<div class="accordion-body">
<header id="title-block-header">
<h1 class="title"> </h1>
</header>
<p><strong>TRUE.</strong> The OLS estimator minimizes <span class="math inline">\| \vec y - X\vec w\|^2</span>. Setting the gradient
to zero gives the normal equations <span class="math display">2X^\top
(X\vec w - \vec y)=0 \;\;\Longrightarrow\;\; X^\top X\,\vec w = X^\top
\vec y.</span></p>
<p>If the columns of <span class="math inline">X</span> are orthonormal,
then <span class="math inline">X^\top X=I</span>, hence <span class="math display">{\vec w}^*=(X^\top X)^{-1}X^\top \vec y =
I^{-1}X^\top \vec y = X^\top \vec y.</span></p>
<p>Since <span class="math inline">X^\top X=I</span> is invertible, the
solution is unique. Geometrically, the coefficients are the inner
products with the orthonormal regressors.</p>
</div>
</div>
</div>
</div>
<p><br></p>
<p>For parts <strong>(e)</strong>‚Äì<strong>(g)</strong>, consider the
following scenario.</p>
<p>Glinda‚Äôs dataset has two features, <span
class="math inline">x^{(1)}</span> and <span
class="math inline">x^{(2)}</span>. She first fits a simple linear
regression model <span class="math inline">H_1(\vec{\alpha})</span>
using only the feature <span class="math inline">x^{(1)}</span>. By
minimizing <span class="math inline">R_{1}</span>, the mean squared
error (MSE) associated with this model, she obtains the optimal
parameter vector <span class="math inline">\vec{\alpha}^{*} =
(\alpha_0^{*}, \alpha_1^{*})</span>. She then fits a second simple
linear regression model <span
class="math inline">H_2(\vec{\beta})</span> using only the feature <span
class="math inline">x^{(2)}</span> and, after minimizing <span
class="math inline">R_{2}</span>, the MSE for this model, obtains <span
class="math inline">\vec{\beta}^{*} = (\beta_0^{*}, \beta_1^{*})</span>.
Finally, she fits a multiple linear regression model using both
features, <span class="math display">H_3(\vec{w},\vec{x}) =
\begin{bmatrix} 1 &amp; x^{(1)} &amp; x^{(2)} \end{bmatrix}
\begin{bmatrix} w_0 \\ w_1 \\ w_2 \end{bmatrix},</span> where <span
class="math inline">x^{(1)}</span> and <span
class="math inline">x^{(2)}</span> are the feature values for a single
observation. Minimizing <span class="math inline">R_{3}</span>, the MSE
for this model, yields the optimal parameter vector <span
class="math inline">\vec{w}^{*} = (w_0^{*}, w_1^{*},
w_2^{*})</span>.</p>
<p><br></p>
<h3 id="problem-2.5">Problem 2.5</h3>
<p><span class="math inline">w^*_1=\alpha^*_1</span> and <span
class="math inline">w^*_2=\beta_1^*</span>.</p>
<p>TRUE or FALSE?</p>
<div id="accordionExample" class="accordion">
<div class="accordion-item">
<h2 class="accordion-header" id="heading2_5">
<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapse2_5" aria-expanded="true" aria-controls="collapse2_5">
Click to view the solution.
</button>
</h2>
<div id="collapse2_5" class="accordion-collapse collapse"
aria-labelledby="heading2_5" data-bs-parent="#accordionExample">
<div class="accordion-body">
<header id="title-block-header">
<h1 class="title"> </h1>
</header>
<p><strong>FALSE.</strong> Adding a second feature generally changes
both coefficients; equality only under special conditions (e.g.,
orthogonality/centering).</p>
</div>
</div>
</div>
</div>
<p><br></p>
<h3 id="problem-2.6">Problem 2.6</h3>
<p><span class="math inline">R_3(\vec{w}^\ast) = R_1(\vec{\alpha}^\ast)
- R_2(\vec{\beta}^\ast)</span></p>
<p>TRUE or FALSE?</p>
<div id="accordionExample" class="accordion">
<div class="accordion-item">
<h2 class="accordion-header" id="heading2_6">
<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapse2_6" aria-expanded="true" aria-controls="collapse2_6">
Click to view the solution.
</button>
</h2>
<div id="collapse2_6" class="accordion-collapse collapse"
aria-labelledby="heading2_6" data-bs-parent="#accordionExample">
<div class="accordion-body">
<header id="title-block-header">
<h1 class="title"> </h1>
</header>
<p><strong>FALSE.</strong> There is no subtraction relation between
optimal MSEs; moreover the RHS can be negative. Typically <span class="math inline">R_3\le\min\{R_1,R_2\}</span>.</p>
</div>
</div>
</div>
</div>
<p><br></p>
<p>Elphaba collects an additional feature <span
class="math inline">x^{(3)}</span> and adds it to Glinda‚Äôs dataset. She
calculates a multiple linear regression model <span
class="math inline">H_4(\vec{v})</span> using all 3 features, and
minimizes the associated MSE <span class="math inline">R_4</span> to
obtain an optimal parameter vector <span
class="math inline">\vec{v}^\ast</span>.</p>
<p><br></p>
<h3 id="problem-2.7">Problem 2.7</h3>
<p><span class="math inline">R_3(\vec{w}^\ast) \geq
R_4(\vec{v}^\ast)</span>.</p>
<p>TRUE or FALSE?</p>
<div id="accordionExample" class="accordion">
<div class="accordion-item">
<h2 class="accordion-header" id="heading2_7">
<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapse2_7" aria-expanded="true" aria-controls="collapse2_7">
Click to view the solution.
</button>
</h2>
<div id="collapse2_7" class="accordion-collapse collapse"
aria-labelledby="heading2_7" data-bs-parent="#accordionExample">
<div class="accordion-body">
<header id="title-block-header">
<h1 class="title"> </h1>
</header>
<p><strong>TRUE.</strong> Adding features cannot increase the minimized
in-sample MSE: <span class="math inline">R_4(\vec v^\ast)\le R_3(\vec
w^\ast)</span>.</p>
</div>
</div>
</div>
</div>
<p><br></p>
<hr />
<h2 id="problem-3">Problem 3</h2>
<ul>
<li>Each plot on the left contains a collection of ten points <span
class="math inline">\{(x_i, y_i)\}_{i=1}^{10}</span>, along with the
line of best fit for an unknown hypothesis function and risk
function.</li>
<li>Next to each plot, clearly state the hypothesis function <span
class="math inline">H(x)</span> and risk function <span
class="math inline">R(\vec{w})</span> which <em>best match</em> the data
and line of best fit. The placeholder <span
class="math inline">\vec{w}</span> can denote either a single parameter
or a vector of multiple parameters.</li>
<li>Your hypothesis functions and risk functions should be borrowed from
the formula bank provided below. <em>Some functions may be used more
than once and others not at all</em>.</li>
<li>In order to receive full credit, you must explain your reasoning
using the box below each part of the problem.</li>
</ul>
<p><strong>Hypothesis functions:</strong> - <span
class="math inline">H(x) = w_0 + w_1x</span> - <span
class="math inline">H(x) = w_0</span> - <span class="math inline">H(x) =
w_0\sin(w_1\,x)</span> - <span class="math inline">H(x) =
w_0+w_1e^{-x}</span> - <span class="math inline">H(x) =
w_0+w_1x+w_2x^2</span></p>
<p><strong>Risk functions:</strong> - <span
class="math inline">R(\vec{w}) = \frac{1}{n}\sum_{i=1}^{n}(H(x_i) -
y_i)^2</span> - <span class="math inline">R(\vec{w}) =
\frac{1}{n}\sum_{i=1}^{10}\ln(H(x_{i}) - y_{i})</span> - <span
class="math inline">R(\vec{w}) = \frac{1}{n}\sum_{i=1}^{n} |H(x_i) -
y_i|</span> - <span class="math inline">R(\vec{w}) = \max_{1\leq i\leq
n} |H(x_i) - y_i|</span> - <span class="math inline">R(\vec{w}) =
(H(x_{10}) - y_{10})^2</span></p>
<p><br></p>
<h3 id="problem-3.1">Problem 3.1</h3>
<p>[Plot a): Constant model with extreme outlier and maximum loss]</p>
<p>What are <span class="math inline">H(x)</span> and <span
class="math inline">R(\vec{w})</span>?</p>
<div id="accordionExample" class="accordion">
<div class="accordion-item">
<h2 class="accordion-header" id="heading3_1">
<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapse3_1" aria-expanded="true" aria-controls="collapse3_1">
Click to view the solution.
</button>
</h2>
<div id="collapse3_1" class="accordion-collapse collapse"
aria-labelledby="heading3_1" data-bs-parent="#accordionExample">
<div class="accordion-body">
<header id="title-block-header">
<h1 class="title"> </h1>
</header>
<p><span class="math inline">H(x)=w_0</span> (constant).</p>
<p><span class="math inline">R(w_0)=\max_i |y_i-w_0|</span> (max
loss).</p>
<p>Reason: the fitted line is the midrange level <span class="math inline">\frac{\min y+\max y}{2}</span>, which minimizes the
worst-case deviation.</p>
</div>
</div>
</div>
</div>
<p><br></p>
<h3 id="problem-3.2">Problem 3.2</h3>
<p>[Plot b): Linear model with outliers and square loss]</p>
<p>What are <span class="math inline">H(x)</span> and <span
class="math inline">R(\vec{w})</span>?</p>
<div id="accordionExample" class="accordion">
<div class="accordion-item">
<h2 class="accordion-header" id="heading3_2">
<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapse3_2" aria-expanded="true" aria-controls="collapse3_2">
Click to view the solution.
</button>
</h2>
<div id="collapse3_2" class="accordion-collapse collapse"
aria-labelledby="heading3_2" data-bs-parent="#accordionExample">
<div class="accordion-body">
<header id="title-block-header">
<h1 class="title"> </h1>
</header>
<p><span class="math inline">H(x)=w_0 + w_1x</span> (linear).</p>
<p><span class="math inline">R(w_0,
w_1)=\frac{1}{n}\sum_{i=1}^n\big(y_i-(w_0 + w_1x_i)\big)^2</span>
(squared loss/OLS).</p>
<p>Reason: line is pulled toward multiple high outliers, characteristic
of L‚ÇÇ sensitivity. Also, if LAD were used, the line would intersect two
or more points, which isn‚Äôt shown here.</p>
</div>
</div>
</div>
</div>
<p><br></p>
<h3 id="problem-3.3">Problem 3.3</h3>
<p>[Plot c): Constant model with two outliers and square loss]</p>
<p>What are <span class="math inline">H(x)</span> and <span
class="math inline">R(\vec{w})</span>?</p>
<div id="accordionExample" class="accordion">
<div class="accordion-item">
<h2 class="accordion-header" id="heading3_3">
<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapse3_3" aria-expanded="true" aria-controls="collapse3_3">
Click to view the solution.
</button>
</h2>
<div id="collapse3_3" class="accordion-collapse collapse"
aria-labelledby="heading3_3" data-bs-parent="#accordionExample">
<div class="accordion-body">
<header id="title-block-header">
<h1 class="title"> </h1>
</header>
<p><span class="math inline">H(x)=w_0</span> (constant).</p>
<p><span class="math inline">R(w_0)=\frac{1}{n}\sum_{i=1}^n
(y_i-w_0)^2</span>.</p>
<p>Reason: horizontal fit at the sample mean (two outliers shift the
mean above the median, below the midrange).</p>
</div>
</div>
</div>
</div>
<p><br></p>
<h3 id="problem-3.4">Problem 3.4</h3>
<p>[Plot d): Quadratic model with outliers]</p>
<p>What are <span class="math inline">H(x)</span> and <span
class="math inline">R(\vec{w})</span>?</p>
<div id="accordionExample" class="accordion">
<div class="accordion-item">
<h2 class="accordion-header" id="heading3_4">
<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapse3_4" aria-expanded="true" aria-controls="collapse3_4">
Click to view the solution.
</button>
</h2>
<div id="collapse3_4" class="accordion-collapse collapse"
aria-labelledby="heading3_4" data-bs-parent="#accordionExample">
<div class="accordion-body">
<header id="title-block-header">
<h1 class="title"> </h1>
</header>
<p><span class="math inline">H(x) = w_0 + w_1x + w_2x^2</span></p>
<p><span class="math inline">R(\vec{w}) = \frac{1}{n}\sum_{i=1}^{n}
(H(x_i) - y_i)^2</span> or <span class="math inline">R(\vec{w}) =
\max_{1\le i\le n} |H(x_i) - y_i)|</span>.</p>
<p>Reason: The curve is influenced by the three outlier points and does
not pass through 3 points, so MAE can be ruled out (By Hwk 3 problem 7).
Thus the only ones that make sense are <span class="math inline">R(\vec{w}) = \frac{1}{n}\sum_{i=1}^{n} (H(x_i) -
y_i)^2</span> or <span class="math inline">R(\vec{w}) = \max_{1\le i\le
n} |H(x_i) - y_i)|</span>, and any justification of these is valid
depending on the student‚Äôs interpretation.</p>
</div>
</div>
</div>
</div>
<p><br></p>
<h3 id="problem-3.5">Problem 3.5</h3>
<p>[Plot e): Linear model with outliers and absolute loss]</p>
<p>What are <span class="math inline">H(x)</span> and <span
class="math inline">R(\vec{w})</span>?</p>
<div id="accordionExample" class="accordion">
<div class="accordion-item">
<h2 class="accordion-header" id="heading3_5">
<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapse3_5" aria-expanded="true" aria-controls="collapse3_5">
Click to view the solution.
</button>
</h2>
<div id="collapse3_5" class="accordion-collapse collapse"
aria-labelledby="heading3_5" data-bs-parent="#accordionExample">
<div class="accordion-body">
<header id="title-block-header">
<h1 class="title"> </h1>
</header>
<p><span class="math inline">H(x)=w_0 + w_1x</span> (linear).</p>
<p><span class="math inline">R(w_0, w_1)=\frac{1}{n}\sum_{i=1}^n
|y_i-(w_0 + w_1x_i)|</span> (LAD / L‚ÇÅ loss).</p>
<p>Reason: line tracks the trend with reduced influence from large
outliers above. It also intersects two or more points, which is another
clue.</p>
</div>
</div>
</div>
</div>
<p><br></p>
<h3 id="problem-3.6">Problem 3.6</h3>
<p>[Plot f): Constant model with five outliers and absolute loss]</p>
<p>What are <span class="math inline">H(x)</span> and <span
class="math inline">R(\vec{w})</span>?</p>
<div id="accordionExample" class="accordion">
<div class="accordion-item">
<h2 class="accordion-header" id="heading3_6">
<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapse3_6" aria-expanded="true" aria-controls="collapse3_6">
Click to view the solution.
</button>
</h2>
<div id="collapse3_6" class="accordion-collapse collapse"
aria-labelledby="heading3_6" data-bs-parent="#accordionExample">
<div class="accordion-body">
<header id="title-block-header">
<h1 class="title"> </h1>
</header>
<p><span class="math inline">H(x) = w_0</span></p>
<p><span class="math inline">R(w_0) = \frac{1}{n}\sum_{i=1}^{n} |H(x_i)
- y_i|</span></p>
<p>The line is flat so it must be a constant model, and the line passed
through the median as opposed to the mean or midrange.</p>
</div>
</div>
</div>
</div>
<p><br></p>
<hr />
<h2 id="section"><span class="math display"> </span></h2>
<h4
id="feedback-find-an-error-still-confused-have-a-suggestion-let-us-know-here.">üëã
Feedback: Find an error? Still confused? Have a suggestion?
<a href="https://forms.gle/WZ71FchnXU1K154d7">Let us know
here</u></a>.</h4>
<hr />
</body>
</html>
